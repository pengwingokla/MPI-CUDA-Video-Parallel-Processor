# Parallel Video Frame Processing using MPI + CUDA

This project demonstrates how to build a **distributed GPU-accelerated image processing pipeline** using **MPI (Message Passing Interface)** and **CUDA (Compute Unified Device Architecture)**. It processes thousands of video frames in parallel by distributing tasks across processes (MPI) and accelerating computation per frame on the GPU (CUDA).

## Overview

This project implements a video processing pipeline with **four different versions**, each demonstrating different parallelization approaches:

1. **Serial Version** (`exec_serial`) - Single-threaded CPU processing, serves as the baseline implementation
2. **CUDA-Only Version** (`exec_cuda_only`) - GPU-accelerated processing using CUDA kernels for parallel frame processing
3. **MPI-Only Version** (`exec_mpi_only`) - Distributed processing using MPI to parallelize across multiple CPU processes
4. **MPI+CUDA Hybrid Version** (`exec_full`) - Combines MPI for distributed processing with CUDA for GPU acceleration on each node

By executing the code, you will have extracted frames from your video, processed them using all four versions, and reassembled the outputs into playable videos for comparison.

## What This Project Does

- Extracts frames from a video (done via a Python script using OpenCV).
- Distributes frame-processing tasks across **multiple MPI workers**.
- Each worker loads a frame, sends it to **CUDA on GPU** to **invert its colors**.
- The processed frame is saved.
- When all frames are processed, they can be reassembled into a new video using FFmpeg.

This setup is ideal for learning hybrid parallel programming that combines CPU task scheduling with GPU computation.


## Tech Stack

- **C (MPI)** for parallel task distribution
- **CUDA** for GPU image inversion
- **stb_image / stb_image_write** for image I/O
- **OpenCV (Python)** for frame extraction (optional)
- **FFmpeg** for video reconstruction (optional)


## Project Layout

```
.
â”œâ”€â”€ bin/                  # Compiled executables (populated after `make`)
â”‚   â”œâ”€â”€ exec_serial
â”‚   â”œâ”€â”€ exec_mpi_only
â”‚   â”œâ”€â”€ exec_cuda_only
â”‚   â””â”€â”€ exec_full
â”œâ”€â”€ build/                # Build artifacts
â”‚   â””â”€â”€ obj/              # Object files (.o files, auto-created)
â”œâ”€â”€ config/               # Configuration files
â”‚   â””â”€â”€ myhost.txt        # MPI hostfile
â”œâ”€â”€ data/                 # Data files
â”‚   â”œâ”€â”€ videos/           # Input video files
â”‚   â””â”€â”€ output/           # Output video files (.mp4)
â”œâ”€â”€ frames/               # JPEG frames extracted from video
â”œâ”€â”€ include/              # Header files
â”œâ”€â”€ logs/                 # Run logs (auto-created)
â”œâ”€â”€ output/               # Processed frames directory
â”œâ”€â”€ scripts/              # Shell scripts for running different versions
â”‚   â”œâ”€â”€ run_all.sh        # End-to-end runner script
â”‚   â”œâ”€â”€ v1_serial.sh
â”‚   â”œâ”€â”€ v2_mpi.sh
â”‚   â”œâ”€â”€ v3_cuda.sh
â”‚   â”œâ”€â”€ v4_full.sh
â”‚   â””â”€â”€ run_full_cluster.sh
â”œâ”€â”€ src/                  # C / CUDA / MPI / Python sources
â”œâ”€â”€ shell.nix             # Nix development shell
â”œâ”€â”€ Makefile              # Top-level build rules
â”œâ”€â”€ README.md             # Project documentation
â””â”€â”€ requirements.txt      # Python dependencies
```

## How It Works

### Step 1: Master-Worker Model (MPI)

- The **master (rank 0)** loads all available image filenames into a task queue.
- Each **worker (rank > 0)** sends a task request to the master.
- The master sends a frame path to the worker.
- The worker processes the frame and returns a result log.

This continues until all frames are processed.

### Step 2: Per-Frame GPU Processing (CUDA)

Each frame is passed to a CUDA kernel that performs **color inversion**: `output_pixel = 255 - input_pixel`

This is done in parallel for each pixel using GPU threads.

### Step 3: Reconstruct Video

Once all frames are processed, `FFmpeg` can be used to stitch them into a video:
```bash
ffmpeg -framerate 30 -i output/frame_%04d.jpg -c:v libx264 output.mp4
```
## Installation & Build
#### Please visit `SIMPLE_INSTRUCTION.md` for a more straightforward instrction

##  Build
To elaborate further, these are the commands in the bash scripts. Note that this only works after frames from the video were extracted and contained in the `/frames` folder.
#### Version 1: Serial (no MPI, no CUDA)
```
./exec_serial
```
#### Version 2: MPI-only
```
.mpirun -np 4 ./exec_mpi_only
```
#### Version 3: CUDA-only
```
./exec_cuda_only
```
#### Version 4: MPI + CUDA (multi-node or multi-GPU)
```
mpirun -np 8 ./exec_full
```

## ðŸ“¦ Output
Each processed frame will be saved to output/frame_XXXX.jpg.

The output images will be the color-inverted versions of the input frames.

## How MPI + CUDA Work Together

MPI Master: Distributes frame tasks to workers
MPI Worker: Receives frame path, processes it
CUDA Kernel: Inverts pixel values on GPU
Task Queue: Dynamically assigns frames as they are available

## Credits
<br>[stb_image](https://github.com/nothings/stb)
<br>[OpenCV](https://opencv.org/)
<br>[OpenMPI](https://www.open-mpi.org/)
<br>NVIDIA CUDA Toolkit